---
title: '0.1 + 0.2 = 0.30000000000000004'
date: 2020-09-14
permalink: /posts/2020/09/0.30000000000000004/
tags:
  - floating-point
---
If you are newbie or experienced coder, I deeply believe you ever encounter a scenario that you do some arithmetic computation on decimal number like:
 `System.out.println(0.1 + 0.2)` and surprisingly, the returned value isn't as expected. You've got 0.30000000000000004. 

However `System.out.println(0.1 + 0.3)` show on my screen `0.4`. 
At the first time, I was thought my computer is lag. It's hard to believe that a modern computer can't produce the result exactly as my old hand calculator can do.
I tried to look up on Google, but I couldn't found any available answer succinct enough to understand. I was daunted. My brain told me: "Let's give up, buddy, we're good without this knowledge". 
As a result, I hardly ever think about this question until someday I found out the way the computer work with the floating-point number. 
If you had been wondering why this magical equation happened like me, this is a time to unveil the behind mechanism's secret.

The first, we have to know that computer doesn't know anything like `0` and `1`. Two number is symbolic number represent for two possible electrical signal state(on/off) of the transistor.
Because of that, the computer must represent everything in the form of `0s` and `1s`. It's look different from our standard decimal system which is include ten number from zero to nine. 
So, as you probably know, when you entered a decimal number, the compiler/interpreter have to convert to binary's digit.

To ensure all computers yield the same result when compute with floating-point number, the `IEEE Standard for Floating-Point Arithmetic (IEEE 754)` come into exists using the idea of scientific notation.
You just factor your number into two parts: a value whose magnitude is in the range of 1 â‰¤ n < 2, and a power of 2 number. For example:
            
$0.1 \quad \textrm{ is2 written as }  \quad 1.6 \times 2^{-4}$          
$0.2 \quad \textrm{ is written as }  \quad 1.6 \times 2^{-3}$   
$0.3 \quad \textrm{ is written as }  \quad 1.2 \times 2^{-2}$    

It's pretty easy to represent integers as binary number using two's complement but in order to convert the floating-point number to binary number, the first step we need convert the floating-point number to the following form: 

$(-1)^{\color{purple}{\textrm{sign bit}}} (1 + \color{red}{\textrm{fraction}})  \times 2^{\textrm{$\color{green}{\textrm{exponent}}$ - bias}}$

![](https://wikimedia.org/api/rest_v1/media/math/render/svg/5f677b27f52fcd521355049a560d53b5c01800e1)

The second step, we need to know how to convert this number represent as scientific notation above to binary number using 64-bit floating-point number format ([IEEE 754](https://en.wikipedia.org/wiki/IEEE_754)), so called double-precision floating-point format, which is the widely popular format in the most modern computers nowadays along with single-precision format and quad-precision format.
64 bits laid out as follows:
 
![](https://s3-ap-southeast-1.amazonaws.com/logbasex.github.io/images/IEEE754-64bit.png)

- The sign occupy 1 bit, sign bit represents whether the number is positive or negative. If it is 0, the value is positive. If it is 1, the value is negative.
- The exponent occupy 11 bits, this is the superscript part in those forms above indicates how many digits after the dot. However, according to IEEE 754 standard, instead of stored exponent as an 11 bits signed two's complement number, coder's life will be easier if represent the exponent as an 11 bits unsigned number by adding the exponent with 1023 ([biasing exponent](https://en.wikipedia.org/wiki/Exponent_bias)) range from `00000000001` to `11111111110` (exclude 0 and 2047, [two special value](https://en.wikipedia.org/wiki/IEEE_754-1985#Positive_and_negative_infinity) ).
- The fraction (sometimes also called the significand or mantissa) occupy 52 bits. If you already familiar with convert integer to binary number, you can convert decimal number to binary number as the same way:


Example: 
- $\begin{array}{rcl}
  0.1 &=& (-1)^0 (1 + \color{red}{\textrm{fraction}}) \times 2^{\textrm{power}}, \quad \textrm{ <=> }\\
  0.1 \quad / \quad 2^{\textrm{power}} &=& 1 + \color{red}{\textrm{fraction}}\\
  \end{array}$
  
  $\begin{array}{rcl}
  0.1 \quad / \quad 2^{-1} &=& 0.2\\
  
  0.1 \quad / \quad 2^{-2} &=& 0.4\\
  
  0.1 \quad / \quad 2^{-3} &=& 0.8\\
  
  0.1 \quad / \quad 2^{-4} &=& 1.6\\
  \end{array}$
  
